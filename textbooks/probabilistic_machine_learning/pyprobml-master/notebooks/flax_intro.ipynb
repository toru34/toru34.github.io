{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flax_intro.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN2xYJXVqbKl+5KCgasUlhl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/probml/pyprobml/blob/master/book1/mlp/flax_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF208fIxvq8m"
      },
      "source": [
        "# Introduction to neural networks using Flax\n",
        "\n",
        "\n",
        "\n",
        "Flax / Linen is a neural net library, built on top of JAX, \"designed to offer an implicit variable management API to save the user from having to manually thread thousands of variables through a complex tree of functions.\" To handle both current and future JAX transforms (configured and composed in any way), Linen Modules are defined as explicit functions of the form\n",
        "$$\n",
        "f(v_{in}, x) \\rightarrow v_{out}, y\n",
        "$$\n",
        "Where $v_{in}$ is the collection of variables (eg. parameters) and PRNG state used by the model, $v_{out}$ the mutated output variable collections, $x$ the input data and $y$ the output data. We illustrate this below. Our tutorial is based on the official [flax intro](https://flax.readthedocs.io/en/latest/notebooks/flax_basics.html) and [linen colab](https://github.com/google/flax/blob/master/docs/notebooks/linen_intro.ipynb). Details are in the [flax source code](https://flax.readthedocs.io/en/latest/_modules/index.html). Note: please be sure to read our [JAX tutorial](https://github.com/probml/pyprobml/blob/master/book1/intro/jax_intro.ipynb) first.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRAzAXYXvztz"
      },
      "source": [
        "import numpy as np\n",
        "#np.set_printoptions(precision=3)\n",
        "np.set_printoptions(formatter={'float': lambda x: \"{0:0.5f}\".format(x)})\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ob8P9ALvkcM",
        "outputId": "573415d3-eba0-4d6a-e51a-674aea067217"
      },
      "source": [
        "# Install the latest JAXlib version.\n",
        "#!pip install --upgrade -q pip jax jaxlib"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 34.0 MB 115 kB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68kI74E1vvEI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4525fc58-0c43-4909-dad9-1172ef516cbf"
      },
      "source": [
        "import jax\n",
        "from jax import lax, random, numpy as jnp\n",
        "key = random.PRNGKey(0)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3dXu6XY6U0H"
      },
      "source": [
        "from typing import Any, Callable, Dict, Iterator, Mapping, Optional, Sequence, Tuple\n",
        "\n",
        "# Useful type aliases\n",
        "Array = jnp.ndarray\n",
        "PRNGKey = Array\n",
        "Batch = Mapping[str, np.ndarray]\n",
        "OptState = Any"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pcNcE9_Qj_l",
        "outputId": "107ed9cb-1d4b-46ab-8032-60836e4b083e"
      },
      "source": [
        "# Install Flax at head:\n",
        "!pip install --upgrade -q git+https://github.com/google/flax.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for flax (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s80k9sonQfDi"
      },
      "source": [
        "import flax\n",
        "from flax.core import freeze, unfreeze\n",
        "from flax import linen as nn\n",
        "from flax import optim\n",
        "\n",
        "from jax.config import config\n",
        "config.enable_omnistaging() # Linen requires enabling omnistaging"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGrUFJYxjyL7"
      },
      "source": [
        "# MLP in vanilla JAX\n",
        "\n",
        "We construct a simple MLP with L hidden layers (relu activation), and scalar output (linear activation).\n",
        "\n",
        "Note: JAX and Flax, like NumPy, are row-based systems, meaning that vectors are represented as row vectors and not column vectors. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWQGVJMP0VMB"
      },
      "source": [
        "# We define the parameter initializers using a signature that is flax-compatible\n",
        "# https://flax.readthedocs.io/en/latest/_modules/jax/_src/nn/initializers.html\n",
        "\n",
        "def weights_init(key, shape, dtype=jnp.float32):\n",
        "  return random.normal(key, shape, dtype)\n",
        "  #return jnp.ones(shape, dtype)\n",
        "\n",
        "def bias_init(key, shape, dtype=jnp.float32):\n",
        "  return jnp.zeros(shape, dtype)\n",
        "\n",
        "def relu(a):\n",
        "  return jnp.maximum(a, 0)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GepkhhTh-9b-"
      },
      "source": [
        "# A minimal MLP class\n",
        "\n",
        "class MLP0():\n",
        "  features: Sequence[int] # number of features in each layer\n",
        "\n",
        "  def __init__(self, features): # class constructor\n",
        "    self.features = features\n",
        "\n",
        "  def init(self, key, x): # initialize parameters\n",
        "    in_size = np.shape(x)[1]\n",
        "    sizes = np.concatenate( ([in_size], self.features) )\n",
        "    nlayers = len(sizes)\n",
        "    params = {}\n",
        "    for i in range(nlayers-1):\n",
        "      in_size = sizes[i]\n",
        "      out_size = sizes[i+1]\n",
        "      subkey1, subkey2, key = random.split(key, num=3)\n",
        "      W = weights_init(subkey1, (in_size, out_size) )\n",
        "      b = bias_init(subkey2, out_size)\n",
        "      params[f'W{i}'] = W\n",
        "      params[f'b{i}'] = b\n",
        "    return params\n",
        "\n",
        "  def apply(self, params, x): # forwards pass\n",
        "    activations = x\n",
        "    nhidden_layers = len(self.features)-1\n",
        "    for i in range(nhidden_layers):\n",
        "      W = params[f'W{i}'];\n",
        "      b = params[f'b{i}'];\n",
        "      outputs = jnp.dot(activations, W) + b\n",
        "      activations = relu(outputs)\n",
        "    # for final layer, no activation function\n",
        "    i = nhidden_layers\n",
        "    outputs = jnp.dot(activations, params[f'W{i}']) + params[f'b{i}']\n",
        "    return outputs\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jFS4SNO0V_I",
        "outputId": "72d9d449-742e-45d1-9641-a4f3a6390e26"
      },
      "source": [
        "key = random.PRNGKey(0)\n",
        "D = 3\n",
        "N = 2\n",
        "x = random.normal(key, (N,D,))\n",
        "layer_sizes = [3,1] # 1 hidden layer of size 3, 1 scalar output\n",
        "\n",
        "model0 = MLP0(layer_sizes)\n",
        "params0 = model0.init(key, x)\n",
        "\n",
        "print('params')\n",
        "for k,v in params0.items():\n",
        "  print(k, v.shape)\n",
        "  print(v)\n",
        "\n",
        "\n",
        "y0 = model0.apply(params0, x)\n",
        "print('\\noutput')\n",
        "print(y0)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "params\n",
            "W0 (3, 3)\n",
            "[[-1.83021 1.18417 0.06777]\n",
            " [0.34588 0.37858 -0.65318]\n",
            " [0.18976 0.45157 -0.33964]]\n",
            "b0 (3,)\n",
            "[0.00000 0.00000 0.00000]\n",
            "W1 (3, 1)\n",
            "[[-1.74905]\n",
            " [1.83313]\n",
            " [-0.23808]]\n",
            "b1 (1,)\n",
            "[0.00000]\n",
            "\n",
            "output\n",
            "[[-0.09538]\n",
            " [2.78382]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBtPT-drBkGA"
      },
      "source": [
        "# Our first flax model\n",
        "\n",
        "Here we recreate the vanilla model in flax. Since we don't specify how the parameters are initialized, the behavior will not be identical to the vanilla model --- we will fix this below, but for now, we focus on model construction.\n",
        "\n",
        "We see that the model is a subclass of `nn.Module`, which is a subclass of Python's dataclass. The child class (written by the user) must define a `model.call(inputs)` method, that applies the function to the input, and a `model.setup()` method, that creates the modules inside this model.\n",
        "\n",
        "The module (parent) class defines two main methods: `model.apply(variables, input`, that applies the function to the input (and variables) to generate an output; and `model.init(key, input)`, that initializes the variables and returns them as a \"frozen dictionary\". This dictionary can contain multiple *kinds* of variables. In the example below, the only kind are parameters, which are immutable variables (that will usually get updated in an external optimization loop, as we show later). The parameters are  automatically named after the corresponding module (here, dense0, dense1, etc).  In this example, both modules are dense layers, so their parameters are a weight matrix (called 'kernel') and a bias vector.\n",
        "\n",
        "The hyper-parameters (in this case, the size of each layer) are stored as attributes of the class, and are specified when the module is constructed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zueDo1r0Qav"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "  features: Sequence[int]\n",
        "  default_attr: int = 42\n",
        "\n",
        "  def setup(self):\n",
        "    print('setup')\n",
        "    self.layers = [nn.Dense(feat) for feat in self.features]\n",
        "\n",
        "  def __call__(self, inputs):\n",
        "    print('call')\n",
        "    x = inputs\n",
        "    for i, lyr in enumerate(self.layers):\n",
        "      x = lyr(x)\n",
        "      if i != len(self.layers) - 1:\n",
        "        x = nn.relu(x)\n",
        "    return x\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoYDn8lX7_ZH",
        "outputId": "9aed2723-3248-417b-9a25-408ef49763d7"
      },
      "source": [
        "key = random.PRNGKey(0)\n",
        "D = 3\n",
        "N = 2\n",
        "x = random.normal(key, (N,D,))\n",
        "layer_sizes = [3,1] # 1 hidden layer of size 3, 1 scalar output\n",
        "\n",
        "print('calling constructor')\n",
        "model = MLP(layer_sizes) # just initialize attributes of the object\n",
        "print('OUTPUT')\n",
        "print(model)\n",
        "\n",
        "print('\\ncalling init')\n",
        "variables = model.init(key, x)  # calls setup then __call___\n",
        "print('OUTPUT')\n",
        "print(variables)\n",
        "\n",
        "\n",
        "print('Calling apply')\n",
        "y = model.apply(variables, x) # calls setup then __call___\n",
        "print(y)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "calling constructor\n",
            "OUTPUT\n",
            "MLP(\n",
            "    # attributes\n",
            "    features = [3, 1]\n",
            "    default_attr = 42\n",
            ")\n",
            "\n",
            "calling init\n",
            "setup\n",
            "call\n",
            "OUTPUT\n",
            "FrozenDict({\n",
            "    params: {\n",
            "        layers_0: {\n",
            "            kernel: DeviceArray([[0.57725, 0.43926, 0.69045],\n",
            "                         [0.02542, 0.50461, 0.56675],\n",
            "                         [0.07185, 0.17350, -0.04227]], dtype=float32),\n",
            "            bias: DeviceArray([0.00000, 0.00000, 0.00000], dtype=float32),\n",
            "        },\n",
            "        layers_1: {\n",
            "            kernel: DeviceArray([[0.24313],\n",
            "                         [0.94535],\n",
            "                         [-0.12602]], dtype=float32),\n",
            "            bias: DeviceArray([0.00000], dtype=float32),\n",
            "        },\n",
            "    },\n",
            "})\n",
            "\n",
            "W0\n",
            "[[0.57725 0.43926 0.69045]\n",
            " [0.02542 0.50461 0.56675]\n",
            " [0.07185 0.17350 -0.04227]]\n",
            "Calling apply\n",
            "setup\n",
            "call\n",
            "[[0.02978]\n",
            " [0.66403]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lwM1j1WksDG"
      },
      "source": [
        "# Compact modules\n",
        "\n",
        "To reduce the amount of boiler plate code, flax makes it possible to define a module just by writing the `call` method, avoiding the need to write a `setup` function. The corresponding layers will be created when the `init` funciton is called, so the input shape can be inferred lazily (when passed an input). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Akq_iXXdktwb",
        "outputId": "2827db63-b8a0-4500-dd78-bd6b49f72065"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "  features: Sequence[int]\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, inputs):\n",
        "    x = inputs\n",
        "    for i, feat in enumerate(self.features):\n",
        "      x = nn.Dense(feat)(x)\n",
        "      if i != len(self.features) - 1:\n",
        "        x = nn.relu(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "model = MLP(layer_sizes)\n",
        "print(model)\n",
        "\n",
        "params = model.init(key, x)\n",
        "print(params)\n",
        "\n",
        "y = model.apply(params, x)\n",
        "print(y)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLP(\n",
            "    # attributes\n",
            "    features = [3, 1]\n",
            ")\n",
            "FrozenDict({\n",
            "    params: {\n",
            "        Dense_0: {\n",
            "            kernel: DeviceArray([[0.28216, 1.03322, 0.07901],\n",
            "                         [0.15159, -0.50100, -0.22373],\n",
            "                         [-0.40327, -0.39875, -0.09402]], dtype=float32),\n",
            "            bias: DeviceArray([0.00000, 0.00000, 0.00000], dtype=float32),\n",
            "        },\n",
            "        Dense_1: {\n",
            "            kernel: DeviceArray([[0.25432],\n",
            "                         [0.76792],\n",
            "                         [0.48329]], dtype=float32),\n",
            "            bias: DeviceArray([0.00000], dtype=float32),\n",
            "        },\n",
            "    },\n",
            "})\n",
            "[[0.56035]\n",
            " [1.07065]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNiuZ54yB7Gj"
      },
      "source": [
        "# Explicit parameter initialization\n",
        "\n",
        "We can control the initialization of the random parameters in each submodule by specifying an init function. Below we show how to initialize our MLP to match the vanilla JAX model. We then check both methods give the same outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W_lEFsU4t04"
      },
      "source": [
        "def make_const_init(x):\n",
        "  def init_params(key, shape, dtype=jnp.float32):\n",
        "    return x\n",
        "  return init_params\n",
        "\n",
        "class MLP_init(nn.Module):\n",
        "  features: Sequence[int]\n",
        "  params_init: Dict\n",
        "\n",
        "  def setup(self):\n",
        "    nlayers = len(self.features)\n",
        "    layers = []\n",
        "    for i in range(nlayers):\n",
        "      W = self.params_init[f'W{i}'];\n",
        "      b = self.params_init[f'b{i}']; \n",
        "      weights_init = make_const_init(W)\n",
        "      bias_init = make_const_init(b)\n",
        "      layer = nn.Dense(self.features[i], kernel_init=weights_init, bias_init=bias_init)\n",
        "      layers.append(layer)\n",
        "    self.layers = layers\n",
        "\n",
        "  def __call__(self, inputs):\n",
        "    x = inputs\n",
        "    for i, lyr in enumerate(self.layers):\n",
        "      x = lyr(x)\n",
        "      if i != len(self.layers) - 1:\n",
        "        x = nn.relu(x)\n",
        "    return x\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R27PhzrLY_zJ",
        "outputId": "adaba9d1-90a4-444b-95be-cef4da0768fe"
      },
      "source": [
        "params_init = params0\n",
        "model = MLP_init(layer_sizes, params_init)\n",
        "print(model)\n",
        "\n",
        "variables = model.init(key, x)\n",
        "params = variables['params']\n",
        "print(params)\n",
        "\n",
        "W0 = params0['W0']\n",
        "W = params['layers_0']['kernel']\n",
        "assert np.allclose(W, W0)\n",
        "\n",
        "y = model.apply(variables, x)\n",
        "print(y)\n",
        "assert np.allclose(y, y0)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLP_init(\n",
            "    # attributes\n",
            "    features = [3, 1]\n",
            "    params_init = {'W0': DeviceArray([[-1.83021, 1.18417, 0.06777],\n",
            "                 [0.34588, 0.37858, -0.65318],\n",
            "                 [0.18976, 0.45157, -0.33964]], dtype=float32), 'b0': DeviceArray([0.00000, 0.00000, 0.00000], dtype=float32), 'W1': DeviceArray([[-1.74905],\n",
            "                 [1.83313],\n",
            "                 [-0.23808]], dtype=float32), 'b1': DeviceArray([0.00000], dtype=float32)}\n",
            ")\n",
            "FrozenDict({\n",
            "    layers_0: {\n",
            "        kernel: DeviceArray([[-1.83021, 1.18417, 0.06777],\n",
            "                     [0.34588, 0.37858, -0.65318],\n",
            "                     [0.18976, 0.45157, -0.33964]], dtype=float32),\n",
            "        bias: DeviceArray([0.00000, 0.00000, 0.00000], dtype=float32),\n",
            "    },\n",
            "    layers_1: {\n",
            "        kernel: DeviceArray([[-1.74905],\n",
            "                     [1.83313],\n",
            "                     [-0.23808]], dtype=float32),\n",
            "        bias: DeviceArray([0.00000], dtype=float32),\n",
            "    },\n",
            "})\n",
            "[[-0.09538]\n",
            " [2.78382]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf8avaA_nGJ1"
      },
      "source": [
        "# Creating your own modules\n",
        "\n",
        "Now we illustrate how to create a module with its own parameters, instead of relying on composing built-in primitives. As an example, we write our own dense layer class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUJ98XpSnS8F",
        "outputId": "ccdc09ef-f87f-4234-d64e-0bd583406851"
      },
      "source": [
        "class SimpleDense(nn.Module):\n",
        "  features: int # num output features for this layer\n",
        "  kernel_init: Callable = nn.initializers.lecun_normal()\n",
        "  bias_init: Callable = nn.initializers.zeros\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, inputs):\n",
        "    features_in = inputs.shape[-1] # infer shape from input\n",
        "    features_out = self.features\n",
        "    kernel = self.param('kernel', self.kernel_init, (features_in, features_out))\n",
        "    bias = self.param('bias', self.bias_init, (features_out,))\n",
        "    outputs = jnp.dot(inputs, kernel) + bias\n",
        "    return outputs\n",
        "\n",
        "\n",
        "model = SimpleDense(features=3)\n",
        "print(model)\n",
        "\n",
        "vars = model.init(key, x)\n",
        "print(vars)\n",
        "\n",
        "y = model.apply(vars, x)\n",
        "print(y)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SimpleDense(\n",
            "    # attributes\n",
            "    features = 3\n",
            "    kernel_init = init\n",
            "    bias_init = zeros\n",
            ")\n",
            "FrozenDict({\n",
            "    params: {\n",
            "        kernel: DeviceArray([[0.32718, 0.05599, 0.17998],\n",
            "                     [-0.12295, 0.70712, 0.28972],\n",
            "                     [0.13731, -0.02853, -0.62830]], dtype=float32),\n",
            "        bias: DeviceArray([0.00000, 0.00000, 0.00000], dtype=float32),\n",
            "    },\n",
            "})\n",
            "[[0.30842 -0.91549 -0.74603]\n",
            " [0.36248 0.24616 0.36943]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJpBh933-GTW"
      },
      "source": [
        "# Stochastic layers\n",
        "\n",
        "Some layers may need a source of randomness. If so, we must pass them a PRNG in the `init` and `apply` functions, in addition to the PRNG used for parameter initialization. We illustrate this below using dropout. We construct two versions, one which is stochastic (for training), and one which is deterministic (for evaluation). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMSpLucO-Yfj",
        "outputId": "9726f1f3-ca25-4946-f9da-29692b1b034c"
      },
      "source": [
        "class Block(nn.Module):\n",
        "  features: int\n",
        "  training: bool\n",
        "  @nn.compact\n",
        "  def __call__(self, inputs):\n",
        "    x = nn.Dense(self.features)(inputs)\n",
        "    x = nn.Dropout(rate=0.5)(x, deterministic=not self.training)\n",
        "    return x\n",
        "\n",
        "N = 1; D = 2;\n",
        "x = random.uniform(key, (N,D))\n",
        "\n",
        "model = Block(features=3, training=True)\n",
        "key = random.PRNGKey(0)\n",
        "variables = model.init({'params': key, 'dropout': key}, x)\n",
        "#variables = model.init(key, x) # cannot share the rng\n",
        "print('variables', variables)\n",
        "\n",
        "# Apply stochastic model\n",
        "for i in range(2):\n",
        "  key, subkey = random.split(key)\n",
        "  y = model.apply(variables, x, rngs={'dropout': subkey})\n",
        "  print(f'train output {i}, ', y)\n",
        "\n",
        "# Now make a deterministic version\n",
        "eval_model = Block(features=3, training=False)\n",
        "key = random.PRNGKey(0)\n",
        "#variables = eval_model.init({'params': key, 'dropout': key}, x)\n",
        "for i in range(2):\n",
        "  key, subkey = random.split(key)\n",
        "  y = eval_model.apply(variables, x, rngs={'dropout': subkey})\n",
        "  print(f'eval output {i}, ', y)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "variables FrozenDict({\n",
            "    params: {\n",
            "        Dense_0: {\n",
            "            kernel: DeviceArray([[0.99988, -0.14086, -0.99796],\n",
            "                         [1.46673, 0.59637, 0.38263]], dtype=float32),\n",
            "            bias: DeviceArray([0.00000, 0.00000, 0.00000], dtype=float32),\n",
            "        },\n",
            "    },\n",
            "})\n",
            "train output 0,  [[0.00000 1.05814 0.00000]]\n",
            "train output 1,  [[3.12202 1.05814 0.32862]]\n",
            "eval output 0,  [[1.56101 0.52907 0.16431]]\n",
            "eval output 1,  [[1.56101 0.52907 0.16431]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHieB2aAumdg"
      },
      "source": [
        "# Stateful layers\n",
        "\n",
        "In addition to parameters, linen modules can contain other kinds of variables, which may be mutable as we illustrate below.\n",
        "Indeed, parameters are just a special case of variable.\n",
        "In particular, this line\n",
        "```\n",
        "p = self.param('param_name', init_fn, shape, dtype)\n",
        "```\n",
        "is a convenient shorthand for this:\n",
        "```\n",
        "p = self.variable('params', 'param_name', lambda s, d: init_fn(self.make_rng('params'), s, d), shape, dtype).value\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAQxx2Tu8xln"
      },
      "source": [
        "## Example: counter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeGNa8zaut41",
        "outputId": "eb8923e0-ed62-46f9-f11b-80dec053e31a"
      },
      "source": [
        "class Counter(nn.Module):\n",
        "  @nn.compact\n",
        "  def __call__(self):\n",
        "    # variable(collection, name, init_fn, *init_args)\n",
        "    counter1 = self.variable('counter', 'count1', lambda: jnp.zeros((), jnp.int32))\n",
        "    counter2 = self.variable('counter', 'count2', lambda: jnp.zeros((), jnp.int32))\n",
        "    is_initialized = self.has_variable('counter', 'count1')\n",
        "    if is_initialized:\n",
        "      counter1.value += 1\n",
        "      counter2.value += 2\n",
        "    return counter1.value, counter2.value\n",
        "\n",
        "\n",
        "model = Counter()\n",
        "print(model)\n",
        "\n",
        "init_variables = model.init(key) # calls the `call` method\n",
        "print('initialized variables:\\n', init_variables)\n",
        "counter = init_variables['counter']['count1']\n",
        "print('counter 1 value', counter)\n",
        "\n",
        "y, mutated_variables = model.apply(init_variables, mutable=['counter'])\n",
        "print('mutated variables:\\n', mutated_variables)\n",
        "print('output:\\n', y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter()\n",
            "initialized variables:\n",
            " FrozenDict({\n",
            "    counter: {\n",
            "        count1: DeviceArray(1, dtype=int32),\n",
            "        count2: DeviceArray(2, dtype=int32),\n",
            "    },\n",
            "})\n",
            "counter 1 value 1\n",
            "mutated variables:\n",
            " FrozenDict({\n",
            "    counter: {\n",
            "        count1: DeviceArray(2, dtype=int32),\n",
            "        count2: DeviceArray(4, dtype=int32),\n",
            "    },\n",
            "})\n",
            "output:\n",
            " (DeviceArray(2, dtype=int32), DeviceArray(4, dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IaC2RT1v65t"
      },
      "source": [
        "## Combining mutable variables and immutable parameters\n",
        "\n",
        "We can combine mutable variables with immutable parameters.\n",
        "As an example, consider a simplified version of batch normalization, which \n",
        " computes the running mean of its inputs, and adds an optimzable offset (bias) term. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXP19telv_Y_"
      },
      "source": [
        "class BiasAdderWithRunningMean(nn.Module):\n",
        "  decay: float = 0.99\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    is_initialized = self.has_variable('params', 'bias')\n",
        "\n",
        "    # variable(collection, name, init_fn, *init_args)\n",
        "    ra_mean = self.variable('batch_stats', 'mean', lambda s: jnp.zeros(s), x.shape[1:])\n",
        "\n",
        "    dummy_mutable = self.variable('mutables', 'dummy', lambda s: 42, 0)\n",
        "\n",
        "    # param(name, init_fn, *init_args)\n",
        "    bias = self.param('bias', lambda rng, shape: jnp.ones(shape), x.shape[1:]) \n",
        "\n",
        "    if is_initialized:\n",
        "      ra_mean.value = self.decay * ra_mean.value + (1.0 - self.decay) * jnp.mean(x, axis=0, keepdims=True)\n",
        "\n",
        "    return x - ra_mean.value + bias\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_WsMGY8xA_x"
      },
      "source": [
        "\n",
        "The intial variables are:\n",
        "params = (bias=1), batch_stats=(mean=0)\n",
        "\n",
        "If we pass in x=ones(N,D), the  running average becomes\n",
        "$$\n",
        "0.99*0 + (1-0.99)*1 = 0.01\n",
        "$$\n",
        "and the output becomes\n",
        "$$\n",
        "1 - 0.01 + 1 = 1.99\n",
        "$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvXKCE8yxiTu",
        "outputId": "4ddb1117-32a0-481d-d8bb-876010d0e821"
      },
      "source": [
        "key = random.PRNGKey(0)\n",
        "N = 2\n",
        "D = 5\n",
        "x = jnp.ones((N,D))\n",
        "model = BiasAdderWithRunningMean()\n",
        "\n",
        "variables = model.init(key, x)\n",
        "print('initial variables:\\n', variables)\n",
        "nonstats, stats = variables.pop('batch_stats')\n",
        "print('nonstats', nonstats)\n",
        "print('stats', stats)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial variables:\n",
            " FrozenDict({\n",
            "    batch_stats: {\n",
            "        mean: DeviceArray([0.00000, 0.00000, 0.00000, 0.00000, 0.00000], dtype=float32),\n",
            "    },\n",
            "    mutables: {\n",
            "        dummy: 42,\n",
            "    },\n",
            "    params: {\n",
            "        bias: DeviceArray([1.00000, 1.00000, 1.00000, 1.00000, 1.00000], dtype=float32),\n",
            "    },\n",
            "})\n",
            "nonstats FrozenDict({\n",
            "    mutables: {\n",
            "        dummy: 42,\n",
            "    },\n",
            "    params: {\n",
            "        bias: DeviceArray([1.00000, 1.00000, 1.00000, 1.00000, 1.00000], dtype=float32),\n",
            "    },\n",
            "})\n",
            "stats FrozenDict({\n",
            "    mean: DeviceArray([0.00000, 0.00000, 0.00000, 0.00000, 0.00000], dtype=float32),\n",
            "})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ytr2_w9U12PT",
        "outputId": "30555a51-9b09-4ef2-8222-98c9b52e4a47"
      },
      "source": [
        "y, mutables = model.apply(variables, x, mutable=['batch_stats'])\n",
        "print('output', y)\n",
        "print('mutables', mutables)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output [[1.99000 1.99000 1.99000 1.99000 1.99000]\n",
            " [1.99000 1.99000 1.99000 1.99000 1.99000]]\n",
            "mutables FrozenDict({\n",
            "    batch_stats: {\n",
            "        mean: DeviceArray([[0.01000, 0.01000, 0.01000, 0.01000, 0.01000]], dtype=float32),\n",
            "    },\n",
            "})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1g2GW3f3B-Z"
      },
      "source": [
        "To call the function with the updated batch stats, we have to stitch together the new mutated state with the old state, as shown below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpBb21A72Bdj",
        "outputId": "d5ce7521-90c4-48a0-a180-4f02be5fe5f8"
      },
      "source": [
        "\n",
        "variables = unfreeze(nonstats)\n",
        "print(variables)\n",
        "variables['batch_stats'] = mutables['batch_stats']\n",
        "variables = freeze(variables)\n",
        "print(variables)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'mutables': {'dummy': 42}, 'params': {'bias': DeviceArray([1.00000, 1.00000, 1.00000, 1.00000, 1.00000], dtype=float32)}}\n",
            "FrozenDict({\n",
            "    mutables: {\n",
            "        dummy: 42,\n",
            "    },\n",
            "    params: {\n",
            "        bias: DeviceArray([1.00000, 1.00000, 1.00000, 1.00000, 1.00000], dtype=float32),\n",
            "    },\n",
            "    batch_stats: {\n",
            "        mean: DeviceArray([[0.01000, 0.01000, 0.01000, 0.01000, 0.01000]], dtype=float32),\n",
            "    },\n",
            "})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa7nH74Y5-Lg"
      },
      "source": [
        "If we pass in x=2*ones(N,D), the running average gets updated to\n",
        "$$\n",
        "0.99 * 0.01 + (1-0.99) * 2.0 = 0.0299\n",
        "$$\n",
        "and the output becomes\n",
        "$$\n",
        "2- 0.0299 + 1 = 2.9701\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2dF2si51QN5",
        "outputId": "6177ee1c-41b7-40e6-d954-d0c1c85b0180"
      },
      "source": [
        "\n",
        "x = 2*jnp.ones((N,D))\n",
        "y, mutables = model.apply(variables, x, mutable=['batch_stats'])\n",
        "print('output', y)\n",
        "print('batch_stats', mutables)\n",
        "\n",
        "assert np.allclose(y, 2.9701)\n",
        "assert np.allclose(mutables['batch_stats']['mean'], 0.0299)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output [[2.97010 2.97010 2.97010 2.97010 2.97010]\n",
            " [2.97010 2.97010 2.97010 2.97010 2.97010]]\n",
            "batch_stats FrozenDict({\n",
            "    batch_stats: {\n",
            "        mean: DeviceArray([[0.02990, 0.02990, 0.02990, 0.02990, 0.02990]], dtype=float32),\n",
            "    },\n",
            "})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnBmgGxOoPKU"
      },
      "source": [
        "# Optimization\n",
        "\n",
        "Flax has several built-in (first-order) optimizers, as we illustrate below on a random linear function. (Note that we can also fit a model defined in flax using some other kind of optimizer, such as that provided by the [optax library](https://github.com/deepmind/optax).)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTHgj_pMra3H",
        "outputId": "d142c2bb-c725-47e6-8cba-5b55f9f16b48"
      },
      "source": [
        "D = 5\n",
        "key = jax.random.PRNGKey(0)\n",
        "params = {'w': jax.random.normal(key, (D,))}\n",
        "print(params)\n",
        "\n",
        "x = jax.random.normal(key, (D,))\n",
        "\n",
        "def loss(params):\n",
        "  w = params['w']\n",
        "  return jnp.dot(x, w)\n",
        "\n",
        "loss_grad_fn = jax.value_and_grad(loss)\n",
        "v, g = loss_grad_fn(params)\n",
        "print(v)\n",
        "print(g)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'w': DeviceArray([0.18784, -1.28334, -0.27109, 1.24906, 0.24447], dtype=float32)}\n",
            "3.375659\n",
            "{'w': DeviceArray([0.18784, -1.28334, -0.27109, 1.24906, 0.24447], dtype=float32)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KdmBHa8oWFY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3695c5f5-339c-4e27-d80e-30d100ddae66"
      },
      "source": [
        "from flax import optim\n",
        "optimizer_def = optim.Momentum(learning_rate=0.1, beta=0.9)\n",
        "print(optimizer_def)\n",
        "\n",
        "optimizer = optimizer_def.create(params) \n",
        "print(optimizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<flax.optim.momentum.Momentum object at 0x7fbd09abceb8>\n",
            "Optimizer(optimizer_def=<flax.optim.momentum.Momentum object at 0x7fbd09abceb8>, state=OptimizerState(step=DeviceArray(0, dtype=int32), param_states={'w': _MomentumParamState(momentum=DeviceArray([0.00000, 0.00000, 0.00000, 0.00000, 0.00000], dtype=float32))}), target={'w': DeviceArray([0.18784, -1.28334, -0.27109, 1.24906, 0.24447], dtype=float32)})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JpgauX_ox_w",
        "outputId": "c649c61c-93ba-41a0-a834-2c254a53a243"
      },
      "source": [
        "for i in range(10):\n",
        "  params = optimizer.target\n",
        "  loss_val, grad = loss_grad_fn(params)\n",
        "  optimizer = optimizer.apply_gradient(grad)\n",
        "  params = optimizer.target\n",
        "  print('step {}, loss {:0.3f}, params {}'.format(i, loss_val, params))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, loss -10.593, params {'w': DeviceArray([-0.71837, 4.90788, 1.03673, -4.77677, -0.93493], dtype=float32)}\n",
            "step 1, loss -12.910, params {'w': DeviceArray([-0.85316, 5.82877, 1.23126, -5.67306, -1.11035], dtype=float32)}\n",
            "step 2, loss -15.332, params {'w': DeviceArray([-0.99326, 6.78590, 1.43345, -6.60462, -1.29268], dtype=float32)}\n",
            "step 3, loss -17.849, params {'w': DeviceArray([-1.13813, 7.77566, 1.64252, -7.56794, -1.48122], dtype=float32)}\n",
            "step 4, loss -20.453, params {'w': DeviceArray([-1.28730, 8.79477, 1.85780, -8.55983, -1.67536], dtype=float32)}\n",
            "step 5, loss -23.133, params {'w': DeviceArray([-1.44033, 9.84031, 2.07866, -9.57743, -1.87453], dtype=float32)}\n",
            "step 6, loss -25.884, params {'w': DeviceArray([-1.59685, 10.90963, 2.30454, -10.61818, -2.07823], dtype=float32)}\n",
            "step 7, loss -28.696, params {'w': DeviceArray([-1.75650, 12.00035, 2.53494, -11.67977, -2.28600], dtype=float32)}\n",
            "step 8, loss -31.565, params {'w': DeviceArray([-1.91897, 13.11033, 2.76941, -12.76010, -2.49745], dtype=float32)}\n",
            "step 9, loss -34.485, params {'w': DeviceArray([-2.08397, 14.23764, 3.00754, -13.85730, -2.71220], dtype=float32)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ITTDWT2ECxC"
      },
      "source": [
        "# Worked example: MLP for MNIST \n",
        "\n",
        "We demonstrate how to fit a shallow MLP to MNIST using Flax.\n",
        "We use this function:\n",
        "https://github.com/probml/pyprobml/blob/master/scripts/fit_flax.py\n",
        "To allow us to edit this file locally (in colab), and push commits back to github, we sync this colab with github. (For details see [this colab](https://colab.research.google.com/github/probml/pyprobml/blob/master/book1/intro/colab_intro.ipynb), the cell labeled \"Working with github\".)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vavamofruHS_"
      },
      "source": [
        "## Import code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3KR7bMQWQ2A",
        "outputId": "6d6f555c-4da0-46dd-975c-ce7daeb24564"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  git_colab.py  __pycache__  pyprobml  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OhoJQUnuE1Q",
        "outputId": "d40b0ab5-8fb3-4286-a925-51e41be70d40"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls /content/drive/MyDrive/ssh/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "id_rsa\tid_rsa.pub  known_hosts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItaIH9dyocZA",
        "outputId": "aebdafd4-9c3c-4bb5-a9a7-f72dbe21f979"
      },
      "source": [
        "!rm -rf probml_tools*.*\n",
        "!wget https://raw.githubusercontent.com/probml/pyprobml/master/scripts/probml_tools.py   \n",
        "import probml_tools as pml"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-19 21:52:51--  https://raw.githubusercontent.com/probml/pyprobml/master/scripts/git_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1243 (1.2K) [text/plain]\n",
            "Saving to: ‘git_colab.py’\n",
            "\n",
            "git_colab.py        100%[===================>]   1.21K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-01-19 21:52:51 (57.6 MB/s) - ‘git_colab.py’ saved [1243/1243]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUYY3-N4uWYh",
        "outputId": "a9e455f0-0b49-4429-ad1d-689f5a6936cc"
      },
      "source": [
        "\n",
        "!rm -rf pyprobml\n",
        "pml.git_ssh(\"git clone https://github.com/probml/pyprobml.git\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "executing command via ssh: git clone git@github.com:probml/pyprobml.git\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjUVc9yKvFFP"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "OQ7d5hfulh7r",
        "outputId": "744eedb7-72d1-4912-fe55-bd79c3fbd3fe"
      },
      "source": [
        "from google.colab import files\n",
        "files.view('/content/pyprobml/scripts/fit_flax.py')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "      ((filepath) => {{\n",
              "        if (!google.colab.kernel.accessAllowed) {{\n",
              "          return;\n",
              "        }}\n",
              "        google.colab.files.view(filepath);\n",
              "      }})(\"/content/pyprobml/scripts/fit_flax.py\")"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKnFd4MFu_jE",
        "outputId": "0d715cf0-8b5c-495d-a1c4-4357d3fe1038"
      },
      "source": [
        "import pyprobml.scripts.fit_flax as ff\n",
        "ff.test()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testing fit-flax\n",
            "train step: 0, loss: 1.9384, accuracy: 0.00\n",
            "train step: 1, loss: 1.8272, accuracy: 0.33\n",
            "FrozenDict({\n",
            "    Dense_0: {\n",
            "        bias: DeviceArray([-0.06866, -0.05334, 0.02114, 0.03266, 0.01460, 0.02043,\n",
            "                     0.03476, 0.03221, 0.04559, -0.07938], dtype=float32),\n",
            "        kernel: DeviceArray([[-0.08550, -0.05451, 0.00159, 0.01994, 0.00922, 0.01030,\n",
            "                      0.02837, 0.02299, 0.01819, 0.02941],\n",
            "                     [0.10214, -0.07613, -0.01284, -0.00828, -0.00770, -0.00438,\n",
            "                      -0.02352, -0.00740, -0.03010, 0.06821],\n",
            "                     [0.10793, 0.00674, 0.00768, -0.00738, -0.00527, -0.00135,\n",
            "                      -0.02333, -0.01150, -0.00446, -0.06905],\n",
            "                     [-0.01783, -0.02995, 0.00988, 0.01451, 0.00608, 0.00938,\n",
            "                      0.01329, 0.01404, 0.01951, -0.03890],\n",
            "                     [-0.02009, 0.03532, 0.01935, 0.01093, 0.00620, 0.00832,\n",
            "                      0.01147, 0.00773, 0.03048, -0.10972]], dtype=float32),\n",
            "    },\n",
            "})\n",
            "test passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMjR542vpGAQ"
      },
      "source": [
        "Edit the file, then commit changes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJXwfqz0-_XJ",
        "outputId": "01fe932f-10f2-4486-c8bd-80ef64c06e68"
      },
      "source": [
        "# If made any local changes to fit_flax.py, save them to github\n",
        "%cd /content/pyprobml\n",
        "pml.git_ssh(\"git add scripts; git commit -m 'push from colab'; git push\")\n",
        "%cd /content"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/pyprobml\n",
            "executing command via ssh: git add scripts; git commit -m 'push from colab'; git push\n",
            "Copying keys from gdrive to local VM\n",
            "Executing git commands\n",
            "Cleanup local VM\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_xSZi3v03pC"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4uNqjBIW0we",
        "outputId": "566ff9c6-ca6f-42a7-dbf4-abf2c78f6d53"
      },
      "source": [
        "\n",
        "\n",
        "def process_record(batch):\n",
        "  image = batch['image']\n",
        "  label = batch['label']\n",
        "  # flatten image to vector\n",
        "  shape = image.get_shape().as_list()\n",
        "  D = np.prod(shape) # no batch dimension\n",
        "  image = tf.reshape(image, (D,))\n",
        "  # rescale to -1..+1\n",
        "  image = tf.cast(image, dtype=tf.float32)\n",
        "  image = ((image / 255.) - .5) * 2. \n",
        "  # convert to standard names\n",
        "  return {'X': image, 'y': label} \n",
        "\n",
        "def load_mnist(split, batch_size):\n",
        "  dataset, info = tfds.load(\"mnist\", split=split, with_info=True)\n",
        "  dataset = dataset.map(process_record)\n",
        "  if split==\"train\":\n",
        "    dataset = dataset.shuffle(10*batch_size, seed=0)\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  dataset = dataset.cache()\n",
        "  dataset = dataset.repeat()\n",
        "  dataset = tfds.as_numpy(dataset) # leave TF behind\n",
        "  num_examples = info.splits[split].num_examples\n",
        "  return iter(dataset), num_examples\n",
        "\n",
        "\n",
        "batch_size = 100\n",
        "train_iter, num_train = load_mnist(\"train\", batch_size)\n",
        "test_iter, num_test = load_mnist(\"test\", batch_size)\n",
        "\n",
        "num_epochs = 3\n",
        "num_steps = num_train // batch_size \n",
        "print(f'{num_epochs} epochs with batch size {batch_size} will take {num_steps} steps')\n",
        "\n",
        "batch = next(train_iter)\n",
        "print(batch['X'].shape)\n",
        "print(batch['y'].shape)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 epochs with batch size 100 will take 600 steps\n",
            "(100, 784)\n",
            "(100,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLiWUSjR05BQ"
      },
      "source": [
        "## Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLwAwqd4Nzvy"
      },
      "source": [
        "class Model(nn.Module):\n",
        "  nhidden: int\n",
        "  nclasses: int\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    if self.nhidden > 0:\n",
        "      x = nn.Dense(self.nhidden)(x)\n",
        "      x = nn.relu(x)\n",
        "    x = nn.Dense(self.nclasses)(x) # logits\n",
        "    x = nn.log_softmax(x) # log probabilities\n",
        "    return x\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JsVFGfU628j"
      },
      "source": [
        "## Training loop\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "KDAJthPTvxI7",
        "outputId": "3f277974-c0db-4c0e-c39d-04648ae16f8f"
      },
      "source": [
        "\n",
        "\n",
        "model = Model(nhidden = 128, nclasses=10) \n",
        "rng = jax.random.PRNGKey(0)\n",
        "num_steps = 200\n",
        "\n",
        "params, history =  ff.fit_model(\n",
        "    model, rng, num_steps, train_iter, test_iter, print_every=20)\n",
        "  \n",
        "display(history)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train step: 0, loss: 2.4736, accuracy: 0.13\n",
            "train step: 20, loss: 1.3480, accuracy: 0.60\n",
            "train step: 40, loss: 0.6385, accuracy: 0.80\n",
            "train step: 60, loss: 0.9009, accuracy: 0.71\n",
            "train step: 80, loss: 0.6118, accuracy: 0.83\n",
            "train step: 100, loss: 0.3172, accuracy: 0.91\n",
            "train step: 120, loss: 0.5050, accuracy: 0.82\n",
            "train step: 140, loss: 0.5362, accuracy: 0.83\n",
            "train step: 160, loss: 0.4464, accuracy: 0.86\n",
            "train step: 180, loss: 0.7583, accuracy: 0.81\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train_loss</th>\n",
              "      <th>train_accuracy</th>\n",
              "      <th>test_loss</th>\n",
              "      <th>test_accuracy</th>\n",
              "      <th>step</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.473641</td>\n",
              "      <td>0.13</td>\n",
              "      <td>2.6066191</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.3479513</td>\n",
              "      <td>0.59999996</td>\n",
              "      <td>1.5261613</td>\n",
              "      <td>0.61</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.6385131</td>\n",
              "      <td>0.79999995</td>\n",
              "      <td>0.5890647</td>\n",
              "      <td>0.82</td>\n",
              "      <td>40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.9008928</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.77288896</td>\n",
              "      <td>0.79999995</td>\n",
              "      <td>60.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.61182076</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0.6232298</td>\n",
              "      <td>0.82</td>\n",
              "      <td>80.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.3172109</td>\n",
              "      <td>0.90999997</td>\n",
              "      <td>0.5554251</td>\n",
              "      <td>0.83</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.50501496</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.45732152</td>\n",
              "      <td>0.85999995</td>\n",
              "      <td>120.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.53616345</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0.5482829</td>\n",
              "      <td>0.84</td>\n",
              "      <td>140.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.44640493</td>\n",
              "      <td>0.85999995</td>\n",
              "      <td>0.61440057</td>\n",
              "      <td>0.84999996</td>\n",
              "      <td>160.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.75831497</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.5472022</td>\n",
              "      <td>0.85999995</td>\n",
              "      <td>180.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   train_loss train_accuracy   test_loss test_accuracy   step\n",
              "0    2.473641           0.13   2.6066191          0.14    0.0\n",
              "1   1.3479513     0.59999996   1.5261613          0.61   20.0\n",
              "2   0.6385131     0.79999995   0.5890647          0.82   40.0\n",
              "3   0.9008928           0.71  0.77288896    0.79999995   60.0\n",
              "4  0.61182076           0.83   0.6232298          0.82   80.0\n",
              "5   0.3172109     0.90999997   0.5554251          0.83  100.0\n",
              "6  0.50501496           0.82  0.45732152    0.85999995  120.0\n",
              "7  0.53616345           0.83   0.5482829          0.84  140.0\n",
              "8  0.44640493     0.85999995  0.61440057    0.84999996  160.0\n",
              "9  0.75831497           0.81   0.5472022    0.85999995  180.0"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "RWv2Sspl8EAN",
        "outputId": "88ac8b9a-9bc6-4921-8e0c-71ec0d61210d"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(history['step'], history['test_accuracy'], 'o-', label='test accuracy')\n",
        "plt.xlabel('num. minibatches')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWe69Z51Q3Kz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}