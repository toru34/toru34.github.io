{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "# Use of this source code is governed by an MIT-style\n",
    "# license that can be found in the LICENSE file or at\n",
    "# https://opensource.org/licenses/MIT.\n",
    "# Notebook authors: Kevin P. Murphy (murphyk@gmail.com)\n",
    "# and Mahmoud Soliman (mjs@aucegypt.edu)\n",
    "\n",
    "# This notebook reproduces figures for chapter 14 from the book\n",
    "# \"Probabilistic Machine Learning: An Introduction\"\n",
    "# by Kevin Murphy (MIT Press, 2021).\n",
    "# Book pdf is available from http://probml.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://opensource.org/licenses/MIT\" target=\"_parent\"><img src=\"https://img.shields.io/github/license/probml/pyprobml\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/probml/pyprobml/blob/master/book1/figures/chapter14_neural_networks_for_images_figures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.1:<a name='14.1'></a> <a name='mlpTranslationInvariance'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Detecting patterns in 2d images using unstructured MLPs does not work well, because the method is not translation invariant. We can design a weight vector to act as a  \\bf matched filter  for detecting the desired cross-shape. This will give a strong response of 5 if the object is on the left, but a weak response of 1 if the object is shifted over to the right. Adapted from Figure 7.16 of <a href='#Stevens2020'>[SAV20]</a> . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.2:<a name='14.2'></a> <a name='imageTemplates'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  We can classify a digit by looking for certain discriminative features (image templates) occuring in the correct (relative) locations. From Figure 5.1 of <a href='#kerasBook'>[Cho17]</a> . Used with kind permission of Francois Chollet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.3:<a name='14.3'></a> <a name='tab:convTable'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Discrete convolution of $\\mathbf  x =[1,2,3,4]$ with $\\mathbf  w =[5,6,7]$ to yield $\\mathbf  z =[5,16,34,52,45,28]$. We see that this operation consists of ``flipping'' $\\mathbf  w $ and then ``dragging'' it over $\\mathbf  x $, multiplying elementwise, and adding up the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.4:<a name='14.4'></a> <a name='conv1d'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  1d cross correlation. Adapted from Figure 15.3.2 of <a href='#dive'>[Zha+20]</a> . Used with kind permission of Aston Zhang. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.4.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.5:<a name='14.5'></a> <a name='diveConv2d'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of 2d cross correlation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reproduce this figure, click the open in colab button: <a href=\"https://colab.research.google.com/github/probml/pyprobml/blob/master/notebooks/conv2d_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.5.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.6:<a name='14.6'></a> <a name='cholletConv2d'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Convolving a 2d image (left) with a $3 \\times 3$ filter (middle) produces a 2d response map (right). The bright spots of the response map correspond to locations in the image which contain diagonal lines sloping down and to the right. From Figure 5.3 of <a href='#kerasBook'>[Cho17]</a> . Used with kind permission of Francois Chollet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.6.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.7:<a name='14.7'></a> <a name='zeroPadding'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Same-convolution (using zero-padding) ensures the output is the same size as the input. Adapted from Figure 8.3 of <a href='#Stevens2020'>[SAV20]</a> . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.7.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.8:<a name='14.8'></a> <a name='CNN2d'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of padding and strides in 2d convolution. (a) We apply ``same convolution'' to a $5 \\times 7$ input (with zero padding) using a $3 \\times 3$ filter to create a $5 \\times 7$ output. (b) Now we use a stride of 2, so the output has size $3 \\times 4$. Adapted from Figures 14.3--14.4 of <a href='#Geron2019'>[Aur19]</a> . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.8_A.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.8_B.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.9:<a name='14.9'></a> <a name='convMultiChannel'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of 2d convolution applied to an input with 2 channels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reproduce this figure, click the open in colab button: <a href=\"https://colab.research.google.com/github/probml/pyprobml/blob/master/notebooks/conv2d_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.9.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.10:<a name='14.10'></a> <a name='CNNhypercolumn'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of a CNN with 2 convolutional layers. The input has 3 color channels. The feature maps at internal layers have multiple channels. The cylinders correspond to hypercolumns, which are feature vectors at a certain location. Adapted from Figure 14.6 of <a href='#Geron2019'>[Aur19]</a> . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.10.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.11:<a name='14.11'></a> <a name='conv1x1'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Mapping 3 channels to 2 using convolution with a filter of size $1 \\times 1 \\times 3 \\times 2$. Adapted from Figure 6.4.2 of <a href='#dive'>[Zha+20]</a> . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.11.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.12:<a name='14.12'></a> <a name='maxPool'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of maxpooling with a 2x2 filter and a stride of 1. Adapted from Figure 6.5.1 of <a href='#dive'>[Zha+20]</a> . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.12.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.13:<a name='14.13'></a> <a name='cnnIntro'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  A simple CNN for classifying images. Adapted from   https://blog.floydhub.com/building-your-first-convnet/ . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.13.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.14:<a name='14.14'></a> <a name='groupNorm'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of different activation normalization methods for a CNN. Each subplot shows a feature map tensor, with N as the batch axis, C as the channel axis, and (H, W) as the spatial axes. The pixels in blue are normalized by the same mean and variance, computed by aggregating the values of these pixels. Left to right: batch norm, layer norm, instance norm, and group norm (with 2 groups of 3 channels). From Figure 2 of <a href='#Wu2018GN'>[YK18]</a> . Used with kind permission of Kaiming He. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.14.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.15:<a name='14.15'></a> <a name='lenet'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  LeNet5, a convolutional neural net for classifying handwritten digits. From Figure 6.6.1 of <a href='#dive'>[Zha+20]</a> . Used with kind permission of Aston Zhang. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.15.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.16:<a name='14.16'></a> <a name='alexnet'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  (a) LeNet5. We assume the input has size $1 \\times 28 \\times 28$, as is the case for MNIST. From Figure 6.6.2 of <a href='#dive'>[Zha+20]</a> . Used with kind permission of Aston Zhang. (b) AlexNet. We assume the input has size $3 \\times 224 \\times 224$, as is the case for (cropped and rescaled) images from ImageNet. From Figure 7.1.2 of <a href='#dive'>[Zha+20]</a> . Used with kind permission of Aston Zhang. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.16_A.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.16_B.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.17:<a name='14.17'></a> <a name='cnnMnist'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Results of applying a CNN to some MNIST images (cherry picked to include some errors). Red is incorrect, blue is correct. (a) After 1 epoch of training. (b) After 2 epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reproduce this figure, click the open in colab button: <a href=\"https://colab.research.google.com/github/probml/pyprobml/blob/master/notebooks/cnn_mnist_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.17_A.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.17_B.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.18:<a name='14.18'></a> <a name='inception'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Inception module. The $1 \\times 1$ convolutional layers reduce the number of channels, keeping the spatial dimensions the same. The parallel pathways through convolutions of different sizes allows the model to learn which filter size to use for each layer. The final depth concatenation block combines the outputs of all the different pathways (which all have the same spatial size). From Figure 7.4.1 of <a href='#dive'>[Zha+20]</a> . Used with kind permission of Aston Zhang. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.18.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.19:<a name='14.19'></a> <a name='googlenet'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  GoogLeNet (slightly simplified from the original). Input is on the left. From Figure 7.4.2 of <a href='#dive'>[Zha+20]</a> . Used with kind permission of Aston Zhang. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.19.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.20:<a name='14.20'></a> <a name='resnetBlock'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  A residual block for a CNN. Left: standard version. Right: version with 1x1 convolution, to allow a change in the number of channels between the input to the block and the output. From Figure 7.6.3 of <a href='#dive'>[Zha+20]</a> . Used with kind permission of Aston Zhang "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.20.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.21:<a name='14.21'></a> <a name='resnet18'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  The ResNet-18 architecture. Each dotted module is a residual block shown in \\cref  fig:resnetBlock . From Figure 7.6.4 of <a href='#dive'>[Zha+20]</a> . Used with kind permission of Aston Zhang "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.21.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.22:<a name='14.22'></a> <a name='densenet'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  (a) Left: a residual block adds the output to the input. Right: a densenet block concatenates the output with the input. (b) Illustration of a densenet. From Figures 7.7.1--7.7.2 of <a href='#dive'>[Zha+20]</a> . Used with kind permission of Aston Zhang. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.22_A.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.22_B.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.23:<a name='14.23'></a> <a name='dilatedConv'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Dilated convolution with a 3x3 filter using rate 1, 2 and 3. From Figure 1 of <a href='#Cui2019cnn'>[Xim+19]</a> . Used with kind permission of Ximin Cui. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.23.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.24:<a name='14.24'></a> <a name='transposedConvDive'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Transposed convolution with 2x2 kernel. From Figure 13.10.1 of <a href='#dive'>[Zha+20]</a> . Used with kind permission of Aston Zhang. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.24.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.25:<a name='14.25'></a> <a name='deconv'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Convolution, deconvolution and transposed convolution. Here $s$ is the stride and $p$ is the padding. From   https://towardsdatascience.com/what-is-transposed-convolutional-layer-40e5e6e31c11 . Used with kind permission of Aqeel Anwar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.25.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.26:<a name='14.26'></a> <a name='depthwiseSeparable'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Depthwise separable convolutions: each of the $C$ input channels undergoes a 2d convolution to produce $C$ output channels, which get combined pointwise (via 1x1 convolution) to produce $D$ output channels. From   https://bit.ly/2L9fm2o . Used with kind permission of Eugenio Culurciello. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.26.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.27:<a name='14.27'></a> <a name='anchorBoxes'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  (a) Illustration of face detection, a special case of object detection. (Photo of author and his wife Margaret, taken at Filoli in California in Feburary, 2018. Image processed by Jonathan Huang using SSD face model.) (b) Illustration of anchor boxes. Adapted from \\citep [Sec 12.5] dive . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.27_A.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.27_B.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.28:<a name='14.28'></a> <a name='maskRCNN'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of object detection and instance segmentation using Mask R-CNN. From   https://github.com/matterport/Mask_RCNN . Used with kind permission of Waleed Abdulla. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.28.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.29:<a name='14.29'></a> <a name='semanticSeg'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of an  \\bf encoder-decoder  (aka  \\bf U-net ) CNN for semantic segmentation The encoder uses convolution (which downsamples), and the decoder uses transposed convolution (which upsamples). From Figure 1 of <a href='#segnet'>[VAR17]</a> . Used with kind permission of Alex Kendall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.29.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.30:<a name='14.30'></a> <a name='Unet'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of the U-Net model for semantic segmentation. Each blue box corresponds to a multi-channel feature map. The number of channels is shown on the top of the box, and the height/width is shown in the bottom left. White boxes denote copied feature maps. The different colored arrows correspond to different operations. From Figure 1 from <a href='#Ronneberger2015'>[OPT15]</a> . Used with kind permission of Olaf Ronenberg. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.30.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.31:<a name='14.31'></a> <a name='densePrediction'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of a multi-task dense prediction problem. From Based on Figure 1 of <a href='#Eigen2015'>[DR15]</a> . Used with kind permission of Rob Fergus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.31.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.32:<a name='14.32'></a> <a name='openPose'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of keypoint detection for body, hands and face using the OpenPose system. From Figure 8 of <a href='#openPose'>[Zhe+18]</a> . Used with kind permission of Yaser Sheikh. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.32.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.33:<a name='14.33'></a> <a name='goose'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Images that maximize the probability of ImageNet classes ``goose'' and ``ostrich'' under a simple Gaussian prior. From   http://yosinski.com/deepvis . Used with kind permission of Jeff Clune. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.33.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.34:<a name='14.34'></a> <a name='TVnorm'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of total variation norm. (a) Input image: a green sea turtle (Used with kind permission of Wikimedia author P. Lindgren). (b) Horizontal deltas. (c) Vertical deltas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.34_A.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.34_B.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.34_C.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.35:<a name='14.35'></a> <a name='deepdreamClassvis'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Images that maximize the probability of certain ImageNet classes under a TV prior. From   https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html . Used with kind permission of Alexander Mordvintsev. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.35.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.36:<a name='14.36'></a> <a name='cnn-vis'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  We visualize ``optimal stimuli'' for neurons in layers Conv 1, 3, 5 and fc8 in the AlexNet architecture, trained on the ImageNet dataset. For Conv5, we also show retrieved real images (under the column ``data driven'') that produce similar activations. Based on the method in <a href='#Mahendran16ijcv'>[MV16]</a> . Used with kind permission of Donglai Wei. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.36.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.37:<a name='14.37'></a> <a name='deepdream'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of DeepDream. The CNN is an Inception classifier trained on ImageNet. (a) Starting image of an Aurelia aurita (also called moon jelly). (b) Image generated after 10 iterations. (c) Image generated after 50 iterations. From   https://en.wikipedia.org/wiki/DeepDream . Used with kind permission of Wikipedia author Martin Thoma. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.37_A.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.37_B.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.37_C.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.38:<a name='14.38'></a> <a name='styleTransfer'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Example output from a neural style transfer system (a) Content image: a green sea turtle (Used with kind permission of Wikimedia author P. Lindgren). (b) Style image: a painting by Wassily Kandinsky called ``Composition 7''. (c) Output of neural style generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.38_A.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.38_B.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.38_C.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.39:<a name='14.39'></a> <a name='neuralStyleD2L'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of how neural style transfer works. Adapted from Figure 12.12.2 of <a href='#dive'>[Zha+20]</a> . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.39.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 14.40:<a name='14.40'></a> <a name='featureMaps3Images'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Schematic representation of 3 kinds of feature maps for 3 different input images. Adapted from Figure 5.16 of <a href='#Foster2019'>[Dav19]</a> . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Click me to run setup { display-mode: \"form\" }\n",
    "try:\n",
    "  if PYPROBML_SETUP_ALREADY_RUN:\n",
    "    print('skipping setup')\n",
    "except:\n",
    "  PYPROBML_SETUP_ALREADY_RUN = True\n",
    "  print('running setup...')\n",
    "  !git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null \n",
    "  %cd -q /pyprobml/scripts\n",
    "  import pyprobml_utils as pml\n",
    "  import colab_utils\n",
    "  import os\n",
    "  os.environ[\"PYPROBML\"] = \"..\" # one above current scripts directory\n",
    "  import google.colab \n",
    "  from google.colab.patches import cv2_imshow\n",
    "  %reload_ext autoreload \n",
    "  %autoreload 2\n",
    "  def show_image(img_path,size=None,ratio=None):\n",
    "      img = colab_utils.image_resize(img_path, size)\n",
    "      cv2_imshow(img)\n",
    "  print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/pyprobml/book1/figures/images/Figure_14.40.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    " <a name='Geron2019'>[Aur19]</a> G. Aur'elien \"Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques for BuildingIntelligent Systems (2nd edition)\". (2019). \n",
    "\n",
    "<a name='kerasBook'>[Cho17]</a> F. Chollet \"Deep learning with Python\". (2017). \n",
    "\n",
    "<a name='Eigen2015'>[DR15]</a> E. David and F. Rob. \"Predicting Depth, Surface Normals and Semantic Labels with aCommon Multi-Scale Convolutional Architecture\". (2015). \n",
    "\n",
    "<a name='Foster2019'>[Dav19]</a> F. David \"Generative Deep Learning: Teaching Machines to Paint, WriteCompose, and Play\". (2019). \n",
    "\n",
    "<a name='Mahendran16ijcv'>[MV16]</a> M. MahendranA and V. VedaldiA. \"Visualizing Deep Convolutional Neural Networks Using Natural Pre-images\". In: ijcv (2016). \n",
    "\n",
    "<a name='Ronneberger2015'>[OPT15]</a> R. Olaf, F. Philipp and B. Thomas. \"U-Net: Convolutional Networks for Biomedical ImageSegmentation\". (2015). \n",
    "\n",
    "<a name='Stevens2020'>[SAV20]</a> E. Stevens, L. Antiga and T. Viehmann. \"Deep Learning with PyTorch\". (2020). \n",
    "\n",
    "<a name='segnet'>[VAR17]</a> B. Vijay, K. Alex and C. Roberto. \"SegNet: A Deep Convolutional Encoder-Decoder Architecture forImage Segmentation\". In: pami (2017). \n",
    "\n",
    "<a name='Cui2019cnn'>[Xim+19]</a> C. Ximin, Z. Ke, G. Lianru, Z. Bing, Y. Dong and R. Jinchang. \"Multiscale Spatial-Spectral Convolutional Network withImage-Based Framework for Hyperspectral Imagery Classification\". In: Remote Sensing (2019). \n",
    "\n",
    "<a name='Wu2018GN'>[YK18]</a> W. Yuxin and H. Kaiming. \"Group Normalization\". (2018). \n",
    "\n",
    "<a name='dive'>[Zha+20]</a> A. Zhang, Z. Lipton, M. Li and A. Smola. \"Dive into deep learning\". (2020). \n",
    "\n",
    "<a name='openPose'>[Zhe+18]</a> C. Zhe, H. Gines, S. Tomas, W. WeiShih-En and S. Yaser. \"OpenPose: Realtime Multi-Person 2D Pose Estimationusing Part Affinity Fields\". abs/1812.08008 (2018). arXiv: 1812.08008 \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
